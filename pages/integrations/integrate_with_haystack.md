---
id: integrate_with_haystack.md
summary: This page goes over how to search for the best answer to questions using Milvus as the Vector Database and Haystack as the LLM framework.
title: æ„å»ºä½¿ç”¨ Milvus å’Œ Haystack çš„æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ
---

# æ„å»ºä½¿ç”¨ Milvus å’Œ Haystack çš„æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ

[Haystack](https://github.com/deepset-ai/haystack) æ˜¯ç”± [deepset](https://www.deepset.ai/) å¼€å‘çš„ä¸€ä¸ªå¼€æºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¡†æ¶ï¼Œç”¨äºæ„å»ºå¯å®šåˆ¶çš„ã€ç”Ÿäº§å°±ç»ªçš„ LLM åº”ç”¨ç¨‹åºã€‚å®ƒæ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¡†æ¶ï¼Œé€šè¿‡ä¸ºåº”ç”¨ç¨‹åºæ„å»ºç”Ÿå‘½å‘¨æœŸçš„æ¯ä¸ªæ­¥éª¤æä¾›å·¥å…·ï¼ŒååŠ©ç¼–æ’å®Œæ•´çš„è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰åº”ç”¨ç¨‹åºã€‚

æœ¬æŒ‡å—å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ [Milvus é›†æˆçš„ Haystack](https://haystack.deepset.ai/integrations/milvus-document-store) åœ¨ Milvus æ–‡æ¡£ä¸Šæ„å»ºä¸€ä¸ªç”± LLM é©±åŠ¨çš„é—®ç­”åº”ç”¨ç¨‹åºã€‚åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œ**Haystack** å’Œ **Milvus** é¦–å…ˆåˆä½œæ‘„å–æ–‡æ¡£é¡µé¢å¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ `MilvusDocumentStore` ä¸­ï¼Œç„¶åä½¿ç”¨ `OpenAIGenerator` é€šè¿‡æ£€ç´¢å¢å¼ºæ¥å›ç­”æŸ¥è¯¢ã€‚

ğŸš€ æŸ¥çœ‹ä½¿ç”¨ `MilvusDocumentStore` è¿›è¡Œ Milvus æ–‡æ¡£é—®ç­”çš„å®Œæ•´åº”ç”¨ç¨‹åº [è¿™é‡Œ](https://github.com/TuanaCelik/milvus-documentation-qa/tree/main)ã€‚

## å®‰è£…

å®‰è£… Haystack å’Œ Milvus é›†æˆï¼š

```bash
pip install milvus-haystack
```

## ä½¿ç”¨

é¦–å…ˆï¼ŒæŒ‰ç…§æ–‡æ¡£ä¸­çš„ '[å¯åŠ¨ Milvus](https://milvus.io/docs/install_standalone-docker.md#Start-Milvus)' è¯´æ˜å¯åŠ¨ Milvus æœåŠ¡ã€‚

ä¸€æ—¦æ‚¨åœ¨ `localhost:19530` ä¸Šæœ¬åœ°è¿è¡Œäº† Milvusï¼Œæ‚¨å¯ä»¥é€šè¿‡åˆå§‹åŒ–ä¸€ä¸ª `MilvusDocumentStore` æ¥å¼€å§‹ä½¿ç”¨ Milvus å’Œ Haystackï¼š

### åˆ›å»ºç´¢å¼•ç®¡é“å¹¶ç´¢å¼•ä¸€äº›æ–‡æ¡£

```python
import os

from haystack import Pipeline
from haystack.components.converters import MarkdownToDocument
from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder
from haystack.components.preprocessors import DocumentSplitter
from haystack.components.writers import DocumentWriter

from milvus_haystack import MilvusDocumentStore
from milvus_haystack.milvus_embedding_retriever import MilvusEmbeddingRetriever

file_paths = [os.path.abspath(__file__)]  # æ‚¨çš„çŸ¥è¯†æ–‡æ¡£åœ¨è¿™é‡Œ

document_store = MilvusDocumentStore(
    connection_args={
        "host": "localhost",
        "port": "19530",
        "user": "",
        "password": "",
        "secure": False,
    },
    drop_old=True,
)
indexing_pipeline = Pipeline()
indexing_pipeline.add_component("converter", MarkdownToDocument())
indexing_pipeline.add_component("splitter", DocumentSplitter(split_by="sentence", split_length=2))
indexing_pipeline.add_component("embedder", SentenceTransformersDocumentEmbedder())
indexing_pipeline.add_component("writer", DocumentWriter(document_store))
indexing_pipeline.connect("converter", "splitter")
indexing_pipeline.connect("splitter", "embedder")
indexing_pipeline.connect("embedder", "writer")
indexing_pipeline.run({"converter": {"sources": file_paths}})

print("æ–‡æ¡£æ•°é‡ï¼š", document_store.count_documents())
```

### åˆ›å»ºæ£€ç´¢ç®¡é“å¹¶å°è¯•ä¸€ä¸ªæŸ¥è¯¢

```python
question = "å¦‚ä½•å®‰è£… Haystack å’Œ Milvus é›†æˆ?"

retrieval_pipeline = Pipeline()
retrieval_pipeline.add_component("embedder", SentenceTransformersTextEmbedder())
retrieval_pipeline.add_component("retriever", MilvusEmbeddingRetriever(document_store=document_store, top_k=3))
retrieval_pipeline.connect("embedder", "retriever")

retrieval_results = retrieval_pipeline.run({"embedder": {"text": question}})

for doc in retrieval_results["retriever"]["documents"]:
    print(doc.content)
    print("-" * 10)
```

### åˆ›å»º RAG ç®¡é“å¹¶å°è¯•ä¸€ä¸ªæŸ¥è¯¢

```python
from haystack.utils import Secret
from haystack.components.embedders import SentenceTransformersTextEmbedder
from haystack.components.builders import PromptBuilder
from haystack.components.generators import OpenAIGenerator

prompt_template = """æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”ä»¥ä¸‹æŸ¥è¯¢ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸åŒ…æ‹¬ç­”æ¡ˆï¼Œè¯·å›å¤ 'I don't know'ã€‚
                     æŸ¥è¯¢ï¼š{{query}}
                     æ–‡æ¡£ï¼š
                     {% for doc in documents %}
                        {{ doc.content }}
                     {% endfor %}
                     ç­”æ¡ˆï¼š
                  """

rag_pipeline = Pipeline()
rag_pipeline.add_component("text_embedder", SentenceTransformersTextEmbedder())
rag_pipeline.add_component("retriever", MilvusEmbeddingRetriever(document_store=document_store, top_k=3))
rag_pipeline.add_component("prompt_builder", PromptBuilder(template=prompt_template))
rag_pipeline.add_component("generator", OpenAIGenerator(api_key=Secret.from_token(os.getenv("OPENAI_API_KEY")),generation_kwargs={"temperature": 0}))
rag_pipeline.connect("text_embedder.embedding", "retriever.query_embedding")
rag_pipeline.connect("retriever.documents", "prompt_builder.documents")
rag_pipeline.connect("prompt_builder", "generator")

results = rag_pipeline.run(
    {
        "text_embedder": {"text": question},
        "prompt_builder": {"query": question},
    }
)
print('RAG answer:', results["generator"]["replies"][0])
```
